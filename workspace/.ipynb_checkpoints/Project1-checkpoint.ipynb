{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 0: Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import featuretools as ft\n",
    "import businesstime\n",
    "import datetime\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from subprocess import check_output\n",
    "from pandas.plotting import scatter_matrix\n",
    "from businesstime.holidays.usa import USFederalHolidays\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\"\"\"\n",
    "\" HyperParams\n",
    "\"\"\"\n",
    "generateDataFlag = True\n",
    "generateFeaturesFlag = True\n",
    "windowSizeGrid = [2,3,4,5,6,7,8,9,10,15,30,60]\n",
    "windowSize = windowSizeGrid[0]\n",
    "\n",
    "def dataGen(data):\n",
    "    if 'FLAG_BusinessHour' not in data.columns:\n",
    "        bt = businesstime.BusinessTime(business_hours = (datetime.time(9), datetime.time(18)),\\\n",
    "                                       weekends=(5, 6), holidays=USFederalHolidays())\n",
    "        dates, isBD = [],[]\n",
    "        for row in data.itertuples(index=True, name='Pandas'):\n",
    "            dates.append(getattr(row, \"date\"))\n",
    "        for row in dates:\n",
    "            boo = bt.isduringbusinesshours(datetime.datetime.strptime(row, '%Y-%m-%d %H:%M:%S'))\n",
    "            isBD.append(1) if boo else isBD.append(0)\n",
    "        data.insert(0, \"FLAG_BusinessHour\", isBD, True)\n",
    "        data['GRAD_CO2'] = np.clip(np.gradient(data['CO2'].rolling(window=windowSize).mean()),-10,10)\n",
    "        data['GRAD_HR'] = np.clip(np.gradient(data['HumidityRatio'].rolling(window=windowSize).mean()),-10,10)\n",
    "        data['HRCO2'] = data['HumidityRatio']*data['CO2']\n",
    "        data['GRAD_HRCO2'] = np.clip(np.gradient(data['HRCO2'].rolling(window=windowSize).mean()),-10,10)\n",
    "        data['index'] = data.index\n",
    "        data.drop(\"Occupancy\", axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def entitySet(data):\n",
    "    es = ft.EntitySet('sensor')\n",
    "    es = es.entity_from_dataframe(index='index', entity_id='log', \\\n",
    "                                  dataframe = data, \\\n",
    "                                  variable_types={f: ft.variable_types.Categorical \n",
    "                                                  for f in data.columns if f.startswith('FLAG_')\n",
    "                                                 })\n",
    "    return es\n",
    "\n",
    "def featureGen(data):\n",
    "    es = entitySet(data)\n",
    "    fm, feature_defs = ft.dfs(\n",
    "        entityset=es, \n",
    "        target_entity='log', \n",
    "        #features_only=True,\n",
    "        trans_primitives=['hour', 'day', 'weekday', 'percentile'],\n",
    "        verbose=True,\n",
    "        #training_window=\"12 hours\"\n",
    "    )\n",
    "    fm['RMEAN_CO2'] = data['CO2'].rolling(window=windowSize).mean()\n",
    "    fm['RMEAN_HR'] = data['HumidityRatio'].rolling(window=windowSize).mean()\n",
    "    fm.fillna(method='bfill', inplace=True)\n",
    "    return fm\n",
    "\n",
    "for windowSize in windowSizeGrid:\n",
    "    dataReady = True if os.path.isfile('../output/trainingWS' + str(windowSize) + '.csv') else False\n",
    "\n",
    "    if dataReady:\n",
    "        fm_train = pd.read_csv('../output/trainingWS' + str(windowSize) + '.csv')\n",
    "        fm_test = pd.read_csv('../output/testWS' + str(windowSize) + '.csv')\n",
    "        fm_test2 = pd.read_csv('../output/test2WS' + str(windowSize) + '.csv')\n",
    "        data_y = pd.read_csv('../output/trainingTarget.csv')\n",
    "        vald_y = pd.read_csv('../output/testTarget.csv')\n",
    "        test_y = pd.read_csv('../output/test2Target.csv')\n",
    "    else:\n",
    "        data = pd.read_csv('../input/datatraining.txt')\n",
    "        val = pd.read_csv('../input/datatest.txt')\n",
    "        test = pd.read_csv('../input/datatest2.txt')\n",
    "        data_y = data['Occupancy']\n",
    "        vald_y = val['Occupancy']\n",
    "        test_y = test['Occupancy']\n",
    "\n",
    "        if generateDataFlag:\n",
    "            data_x = dataGen(data)\n",
    "            vald_x = dataGen(val)\n",
    "            test_x = dataGen(test)\n",
    "        else:\n",
    "            data_x = data\n",
    "            vald_x = val\n",
    "            test_x = test\n",
    "\n",
    "        if generateFeaturesFlag:\n",
    "            fm_train = featureGen(data_x).drop(['Humidity'],axis=1)\n",
    "            fm_test  = featureGen(vald_x).drop(['Humidity'],axis=1)\n",
    "            fm_test2 = featureGen(test_x).drop(['Humidity'],axis=1)\n",
    "        else:\n",
    "            fm_train = data_x.drop(['date','time','index','Humidity'],axis=1)\n",
    "            fm_test  = vald_x.drop(['date','time','index','Humidity'],axis=1)\n",
    "            fm_test2 = test_x.drop(['date','time','index','Humidity'],axis=1)\n",
    "\n",
    "        fm_train = fm_train.drop(data.index[3830:3834]) # light anomaly detected, drop rows\n",
    "        data_y = data_y.drop(data.index[3830:3834]) # light anomaly detected, drop rows\n",
    "        \n",
    "        fm_train.to_csv('../output/trainingWS' + str(windowSize) + '.csv')\n",
    "        fm_test.to_csv('../output/testWS' + str(windowSize) + '.csv')\n",
    "        fm_test2.to_csv('../output/test2WS' + str(windowSize) + '.csv')\n",
    "        data_y.to_csv('../output/trainingTarget.csv')\n",
    "        vald_y.to_csv('../output/testTarget.csv')\n",
    "        test_y.to_csv('../output/test2Target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8108</th>\n",
       "      <td>8114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>8115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>8116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>8117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>8118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>8119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>8120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>8121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>8122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>8123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>8124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>8125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>8126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>8127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>8128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>8129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>8130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>8131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>8132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>8133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>8134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>8135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>8136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>8137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>8138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>8139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>8140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>8141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>8142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8137</th>\n",
       "      <td>8143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1  1.1\n",
       "0        2    1\n",
       "1        3    1\n",
       "2        4    1\n",
       "3        5    1\n",
       "4        6    1\n",
       "5        7    1\n",
       "6        8    1\n",
       "7        9    1\n",
       "8       10    1\n",
       "9       11    1\n",
       "10      12    1\n",
       "11      13    1\n",
       "12      14    1\n",
       "13      15    1\n",
       "14      16    1\n",
       "15      17    0\n",
       "16      18    0\n",
       "17      19    0\n",
       "18      20    0\n",
       "19      21    0\n",
       "20      22    0\n",
       "21      23    0\n",
       "22      24    0\n",
       "23      25    0\n",
       "24      26    0\n",
       "25      27    0\n",
       "26      28    0\n",
       "27      29    0\n",
       "28      30    0\n",
       "29      31    0\n",
       "...    ...  ...\n",
       "8108  8114    1\n",
       "8109  8115    1\n",
       "8110  8116    1\n",
       "8111  8117    1\n",
       "8112  8118    1\n",
       "8113  8119    1\n",
       "8114  8120    1\n",
       "8115  8121    1\n",
       "8116  8122    1\n",
       "8117  8123    1\n",
       "8118  8124    1\n",
       "8119  8125    1\n",
       "8120  8126    1\n",
       "8121  8127    1\n",
       "8122  8128    1\n",
       "8123  8129    1\n",
       "8124  8130    1\n",
       "8125  8131    1\n",
       "8126  8132    1\n",
       "8127  8133    1\n",
       "8128  8134    1\n",
       "8129  8135    1\n",
       "8130  8136    1\n",
       "8131  8137    1\n",
       "8132  8138    1\n",
       "8133  8139    1\n",
       "8134  8140    1\n",
       "8135  8141    1\n",
       "8136  8142    1\n",
       "8137  8143    1\n",
       "\n",
       "[8138 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part I: Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (8138,2) into shape (8138)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/seaborn/utils.py\u001b[0m in \u001b[0;36mcategorical_order\u001b[0;34m(values, order)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                 \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'cat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/seaborn/utils.py\u001b[0m in \u001b[0;36mcategorical_order\u001b[0;34m(values, order)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'unique'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bf8530c3ba83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Occupied: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Empty: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# labels are badly skewed, need stratified sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mcountplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3551\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3553\u001b[0;31m                           errcolor, errwidth, capsize, dodge)\n\u001b[0m\u001b[1;32m   3554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3555\u001b[0m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0;32m-> 1607\u001b[0;31m                                  order, hue_order, units)\n\u001b[0m\u001b[1;32m   1608\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;31m# Get the order on the categorical axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0mgroup_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;31m# Group the numeric data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/seaborn/utils.py\u001b[0m in \u001b[0;36mcategorical_order\u001b[0;34m(values, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_ensure_arraylike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;31m# making a 1D array that contains list-likes is a bit tricky:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (8138,2) into shape (8138)"
     ]
    }
   ],
   "source": [
    "ax = sns.countplot(data_y,label=\"Count\")\n",
    "E, O = data_y.value_counts()\n",
    "print('Number of Occupied: ', O)\n",
    "print('Number of Empty: ', E)\n",
    "plt.figure(figsize=(15,15)) # labels are badly skewed, need stratified sampling\n",
    "\n",
    "stdscaler = preprocessing.StandardScaler()\n",
    "minmaxscaler = preprocessing.MinMaxScaler()\n",
    "data_n_2 = pd.DataFrame(stdscaler.fit_transform(fm_train), columns=fm_train.columns)\n",
    "data = pd.concat([data_y,data_n_2],axis=1)\n",
    "data = pd.melt(data,id_vars=\"Occupancy\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"Occupancy\", data=data,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.boxplot(x=\"features\", y=\"value\", hue=\"Occupancy\", data=data)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "scatter_matrix(data_n_2, c=data_y, alpha=0.2, figsize=(50,50), diagonal='density')\n",
    "fig = plt.gcf()\n",
    "fig.savefig('../output/scattermatrix.png',bbox_inches='tight',pad_inches=0.1) \n",
    "\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(data_n_2.corr(), annot=True, linewidths=.5, fmt= '.1f')\n",
    "\n",
    "fm_train.to_csv('../output/trainingWS' + windowSize + '.csv')\n",
    "fm_test.to_csv('../output/testWS' + windowSize + '.csv')\n",
    "fm_test2.to_csv('../output/test2WS' + windowSize + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part IIa: Regular RF Pipeline with Support Vector Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.feature_selection import SelectFromModel,SelectKBest,chi2,mutual_info_classif\n",
    "from functools import partial\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "clf = Pipeline([\n",
    "        ('scale', preprocessing.StandardScaler()),\n",
    "        ('feature_selection', SelectFromModel(LinearSVC(C=0.0001,penalty=\"l1\",dual=False))),\n",
    "        ('classification', RandomForestClassifier(random_state=1))\n",
    "    ])\n",
    "\n",
    "for train, test in skf.split(fm_train, data_y):\n",
    "    x_train, y_train = fm_train.iloc[train], data_y.iloc[train]\n",
    "    clf.fit(x_train, y_train)\n",
    "    x_test, y_test = fm_train.iloc[test], data_y.iloc[test]\n",
    "    ac = accuracy_score(y_test,clf.predict(x_test))\n",
    "    cm = confusion_matrix(y_test, clf.predict(x_test))\n",
    "    print('Accuracy is: ', ac)\n",
    "    \n",
    "x_test, y_test = fm_test, vald_y\n",
    "ac = accuracy_score(y_test,clf.predict(x_test))\n",
    "print('Accuracy of test1 is: ', ac)\n",
    "\n",
    "x_test, y_test = fm_test2, test_y\n",
    "ac = accuracy_score(y_test,clf.predict(x_test))\n",
    "print('Accuracy of test2 is: ', ac)\n",
    "cm = confusion_matrix(y_test, clf.predict(x_test))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part IIb: RF Pipeline with K-Best Mutual Info Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_train = pd.DataFrame(stdscaler.fit_transform(fm_train), columns=fm_train.columns)\n",
    "fm_test = pd.DataFrame(stdscaler.fit_transform(fm_test), columns=fm_train.columns)\n",
    "fm_test2 = pd.DataFrame(stdscaler.fit_transform(fm_test2), columns=fm_train.columns)\n",
    "\n",
    "for train, test in skf.split(fm_train, data_y):\n",
    "    x_train, y_train = fm_train.iloc[train], data_y.iloc[train]\n",
    "    # find best scored features\n",
    "    select_feature = SelectKBest(score_func=mutual_info_classif, k=12).fit(x_train,y_train)\n",
    "    #print('Score list:', select_feature.scores_)\n",
    "    #print('Feature list:', x_train.columns)\n",
    "    x_train_2 = select_feature.transform(x_train)\n",
    "    x_test_2 = select_feature.transform(x_test)\n",
    "    #random forest classifier with n_estimators=10 (default)\n",
    "    clf_rf_2 = RandomForestClassifier()      \n",
    "    clr_rf_2 = clf_rf_2.fit(x_train_2,y_train)\n",
    "    ac_2 = accuracy_score(y_test,clf_rf_2.predict(x_test_2))\n",
    "    print('Accuracy is: ',ac_2)\n",
    "    \n",
    "x_test, y_test = fm_test, vald_y\n",
    "x_test = select_feature.transform(x_test)\n",
    "ac = accuracy_score(y_test,clf_rf_2.predict(x_test))\n",
    "print('Accuracy of test1 is: ', ac)\n",
    "\n",
    "x_test, y_test = fm_test2, test_y\n",
    "x_test = select_feature.transform(x_test)\n",
    "ac = accuracy_score(y_test,clf_rf_2.predict(x_test))\n",
    "print('Accuracy of test2 is: ', ac)\n",
    "cm = confusion_matrix(y_test, clf_rf_2.predict(x_test))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%99 accuracy is easily matched with RF methods, however, in the literature we have seen less varianced accuracies with other ML methods. Let's save the dataframes here and search for a better approach with autoML (TPOT), semi-autoML with hyperparameter search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
